{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG16_SGS.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9uych1OHW7q"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aqjppRJHcD9"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import IPython.display as display\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LqzfnTpHeXL"
      },
      "source": [
        "data_dir = '/content/drive/My Drive/Colab Notebooks/data'\n",
        "train_data_dir = '/content/drive/My Drive/Colab Notebooks/data/train'\n",
        "test_data_dir = '/content/drive/My Drive/Colab Notebooks/data/test' \n",
        "model_path = '/content/drive/My Drive/Colab Notebooks/data/SGS_BasicTransferLearningModel.h5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4aWHevTHg5l"
      },
      "source": [
        "NUM_CLASSES = 10\n",
        "CHANNELS = 3\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "\n",
        "aug_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,                                                                      \n",
        "                                                                      samplewise_center=True, \n",
        "                                                                      samplewise_std_normalization=True,\n",
        "                                                                      rotation_range=60,\n",
        "                                                                      width_shift_range=0.2,\n",
        "                                                                      height_shift_range=0.2,\n",
        "                                                                      shear_range=0.2,\n",
        "                                                                      zoom_range=0.2,\n",
        "                                                                      horizontal_flip=True,\n",
        "                                                                      vertical_flip=True,\n",
        "                                                                      fill_mode='nearest',\n",
        "                                                                      validation_split = 0.2)\n",
        "norm_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,                                                                      \n",
        "                                                               samplewise_center=False, \n",
        "                                                               samplewise_std_normalization=False,\n",
        "                                                               validation_split = 0.2)\n",
        "\n",
        "\n",
        "aug_train_generator = aug_datagen.flow_from_directory(train_data_dir,\n",
        "                                                    target_size = (224,224),\n",
        "                                                    batch_size = 64,\n",
        "                                                    class_mode = 'binary',\n",
        "                                                    shuffle=True,\n",
        "                                                    subset = 'training')\n",
        "\n",
        "aug_validation_generator = aug_datagen.flow_from_directory(train_data_dir,\n",
        "                                                    target_size = (224,224),\n",
        "                                                    batch_size = 64,\n",
        "                                                    class_mode = 'binary',\n",
        "                                                    shuffle=True,\n",
        "                                                    subset = 'validation')\n",
        "\n",
        "norm_train_generator = norm_datagen.flow_from_directory(train_data_dir,\n",
        "                                                    target_size = (224,224),\n",
        "                                                    batch_size = 64,\n",
        "                                                    class_mode = 'binary',\n",
        "                                                    shuffle=True,\n",
        "                                                    subset = 'training')\n",
        "\n",
        "norm_validation_generator = norm_datagen.flow_from_directory(train_data_dir,\n",
        "                                                    target_size = (224,224),\n",
        "                                                    batch_size = 64,\n",
        "                                                    class_mode = 'binary',\n",
        "                                                    shuffle=True,\n",
        "                                                    subset = 'validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zydXxbnLHjaF"
      },
      "source": [
        "\n",
        "base_model_VGC16 = tf.keras.applications.VGG16(input_shape=(224,224,3),\n",
        "                                               include_top=False,\n",
        "                                               weights=None,\n",
        "                                               classes = 10\n",
        "                                    )\n",
        "base_model_VGC16.trainable = True\n",
        "\n",
        "Layer1 = tf.keras.layers.Flatten()\n",
        "Layer2 = tf.keras.layers.Dense(1024,activation='relu')\n",
        "Layer3 = tf.keras.layers.Dropout(.6)\n",
        "Layer4 = tf.keras.layers.Dense(128,activation='relu')\n",
        "Layer5 = tf.keras.layers.Dropout(.5)\n",
        "Layer6 = tf.keras.layers.Dense(64,activation='relu')\n",
        "Layer7 = tf.keras.layers.Dropout(.5)\n",
        "Layer8 = tf.keras.layers.Dense(8,activation='relu')\n",
        "Layer9 = tf.keras.layers.Dropout(.2)\n",
        "prediction_layer = tf.keras.layers.Dense(1,activation='sigmoid')\n",
        "\n",
        "Final_model_VGC16 = tf.keras.Sequential([\n",
        "  base_model_VGC16,\n",
        "  Layer1,\n",
        "  Layer2,\n",
        "  Layer3,\n",
        "  Layer4,\n",
        "  Layer5,                                        \n",
        "  Layer6,\n",
        "  Layer7,\n",
        "  Layer8,\n",
        "  Layer9,\n",
        "  prediction_layer\n",
        "])\n",
        "Final_model_VGC16.summary()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3tmo0bPIJgU"
      },
      "source": [
        "from tensorflow import keras\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                              patience=5, min_lr=0.001)\n",
        "\n",
        "def scheduler(epoch):\n",
        "  if epoch < 10:\n",
        "    return 0.001\n",
        "  else:\n",
        "    return 0.001 * tf.math.exp(0.1 * (10 - epoch))\n",
        "\n",
        "callback1 = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "callback2 = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=4)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmZHjUg0H505"
      },
      "source": [
        "Final_model_VGC16.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
        "              loss=keras.losses.BinaryCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "Final_model_VGC16.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kiO5U6PITR3"
      },
      "source": [
        "\n",
        "nb_epochs = 100\n",
        "batch_size = 64\n",
        "history = Final_model_VGC16.fit(\n",
        "    norm_train_generator,\n",
        "    steps_per_epoch = norm_train_generator.samples // batch_size,\n",
        "    validation_data = norm_validation_generator, \n",
        "    validation_steps = norm_validation_generator.samples // batch_size,\n",
        "    epochs = nb_epochs,\n",
        "    callbacks = [callback1,callback2],\n",
        "    )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAoKDWipIqq_"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0,1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,max(plt.ylim())])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QtsBomDIu_N"
      },
      "source": [
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(test_data_dir,\n",
        "                                                    target_size = (224,224),\n",
        "                                                    batch_size = 1,\n",
        "                                                    class_mode = 'binary')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRwM2Ld1Iy7e"
      },
      "source": [
        "c = 0\n",
        "for i in range(660):\n",
        "  temp = Final_model_VGC16.predict(test_generator[i][0]) \n",
        "  if  temp > 0.5:\n",
        "    temp = 1\n",
        "  else:\n",
        "    temp = 0\n",
        "  if temp == test_generator[i][1].astype('int32')[0]:\n",
        "    c+=1    \n",
        "print(c)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugf06cjLI2fL"
      },
      "source": [
        "Final_model_VGC16.evaluate(test_generator,batch_size=1,steps=660)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9HHEVBgI8v0"
      },
      "source": [
        "Final_model_VGC16.save('/content/drive/My Drive/Colab Notebooks/data/VGG16FineTunedwithoutSGS.h5') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsqDgTXKIiZU"
      },
      "source": [
        "base_model_VGC16 = tf.keras.applications.VGG16(input_shape=(224,224,3),\n",
        "                                               include_top=False,\n",
        "                                               weights=None,\n",
        "                                               classes = 10\n",
        "                                    )\n",
        "base_model_VGC16.trainable = True\n",
        "\n",
        "Layer1 = tf.keras.layers.Flatten()\n",
        "Layer2 = tf.keras.layers.Dense(1024,activation='relu')\n",
        "Layer3 = tf.keras.layers.Dropout(.6)\n",
        "Layer4 = tf.keras.layers.Dense(128,activation='relu')\n",
        "Layer5 = tf.keras.layers.Dropout(.5)\n",
        "Layer6 = tf.keras.layers.Dense(64,activation='relu')\n",
        "Layer7 = tf.keras.layers.Dropout(.5)\n",
        "Layer8 = tf.keras.layers.Dense(8,activation='relu')\n",
        "Layer9 = tf.keras.layers.Dropout(.2)\n",
        "prediction_layer = tf.keras.layers.Dense(1,activation='sigmoid')\n",
        "\n",
        "Final_model_VGC16 = tf.keras.Sequential([\n",
        "  base_model_VGC16,\n",
        "  Layer1,\n",
        "  Layer2,\n",
        "  Layer3,\n",
        "  Layer4,\n",
        "  Layer5,                                        \n",
        "  Layer6,\n",
        "  Layer7,\n",
        "  Layer8,\n",
        "  Layer9,\n",
        "  prediction_layer\n",
        "])\n",
        "Final_model_VGC16.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07Qibv_qJHKI"
      },
      "source": [
        "Final_model_VGC16.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
        "              loss=keras.losses.BinaryCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "Final_model_VGC16.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNYdfXYtJM1a"
      },
      "source": [
        "\n",
        "nb_epochs = 100\n",
        "batch_size = 64\n",
        "history = Final_model_VGC16.fit(\n",
        "    norm_train_generator,\n",
        "    steps_per_epoch = aug_train_generator.samples // batch_size,\n",
        "    validation_data = aug_validation_generator, \n",
        "    validation_steps = aug_validation_generator.samples // batch_size,\n",
        "    epochs = nb_epochs,\n",
        "    callbacks = [callback1,callback2],\n",
        "    )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tenxlr7JQRB"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0,1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,max(plt.ylim())])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEMY9wsdJZi1"
      },
      "source": [
        "c = 0\n",
        "for i in range(660):\n",
        "  temp = Final_model_VGC16.predict(test_generator[i][0]) \n",
        "  if  temp > 0.5:\n",
        "    temp = 1\n",
        "  else:\n",
        "    temp = 0\n",
        "  if temp == test_generator[i][1].astype('int32')[0]:\n",
        "    c+=1    \n",
        "print(c)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Oc7cqBAJcq0"
      },
      "source": [
        "Final_model_VGC16.evaluate(test_generator,batch_size=1,steps=660)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M01h_fs7Jfnc"
      },
      "source": [
        "Final_model_VGc16.save('/content/drive/My Drive/Colab Notebooks/data/VGG16FineTunedwithSGS.h5') "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}