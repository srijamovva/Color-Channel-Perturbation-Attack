{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEMjtuQ030oT"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import os\n",
        "from skimage import io\n",
        "import numpy as np\n",
        "from keras import backend as K\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, DepthwiseConv2D\n",
        "from keras.layers import Concatenate\n",
        "from keras.models import load_model\n",
        "from keras.optimizers import SGD, Adam, RMSprop\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping, LearningRateScheduler, CSVLogger\n",
        "from keras.callbacks import Callback\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "import copy\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5gMdq3S35uo"
      },
      "outputs": [],
      "source": [
        "class cifar10vgg:\n",
        "    def __init__(self,train=True, ccp_augment=False):\n",
        "        self.num_classes = 10\n",
        "        self.weight_decay = 0.0005\n",
        "        self.x_shape = [32,32,3]\n",
        "\n",
        "        self.model = self.build_model()\n",
        "        if train:\n",
        "            self.model = self.train(self.model, ccp_augment)\n",
        "        else:\n",
        "            self.model.load_weights('cifar10vgg.h5')\n",
        "\n",
        "\n",
        "    def build_model(self):\n",
        "\n",
        "        model = Sequential()\n",
        "        weight_decay = self.weight_decay\n",
        "\n",
        "        model.add(Conv2D(64, (3, 3), padding='same',\n",
        "                         input_shape=self.x_shape,kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.3))\n",
        "\n",
        "        model.add(Conv2D(64, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "        model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.4))\n",
        "\n",
        "        model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.4))\n",
        "\n",
        "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.4))\n",
        "\n",
        "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.4))\n",
        "\n",
        "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.4))\n",
        "\n",
        "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.4))\n",
        "\n",
        "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.4))\n",
        "\n",
        "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Dropout(0.5))\n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(512,kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(self.num_classes))\n",
        "        model.add(Activation('softmax'))\n",
        "        return model\n",
        "\n",
        "\n",
        "    def normalize(self,X_train,X_test):\n",
        "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
        "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
        "        X_train = (X_train-mean)/(std+1e-7)\n",
        "        X_test = (X_test-mean)/(std+1e-7)\n",
        "        return X_train, X_test\n",
        "\n",
        "    def normalize_production(self,x):\n",
        "        mean = np.mean(x)\n",
        "        std = np.std(x)\n",
        "        return (x-mean)/(std+1e-7)\n",
        "\n",
        "    def predict(self,x,normalize=True,batch_size=50):\n",
        "        if normalize:\n",
        "            x = self.normalize_production(x)\n",
        "        return self.model.predict(x,batch_size)\n",
        "\n",
        "\n",
        "    def train(self,model, ccp_augment=False):\n",
        "\n",
        "        batch_size = 128\n",
        "        maxepoches = 250\n",
        "        learning_rate = 0.1\n",
        "        lr_decay = 1e-6\n",
        "        lr_drop = 20\n",
        "\n",
        "        def change_brightness(image, alpha, beta):\n",
        "          new_image = np.zeros(image.shape, np.int64)\n",
        "          new_image = np.clip(alpha*image, 0, 255)\n",
        "          return new_image\n",
        "          \n",
        "        def CCP_Attack_Brightness(image, transform):\n",
        "          img = copy.copy(image)\n",
        "          for channel in range(img.shape[2]):\n",
        "            temp1 = image[:,:,0]\n",
        "            temp2 = image[:,:,1]\n",
        "            temp3 = image[:,:,2]\n",
        "\n",
        "            temp = temp1 * transform[channel][0] + temp2 * transform[channel][1] + temp3 * transform[channel][2]\n",
        "\n",
        "            img[:,:,channel] = temp/3\n",
        "\n",
        "          img1 = change_brightness(img, 2, 0)\n",
        "          return img1\n",
        "\n",
        "        (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "        if ccp_augment:\n",
        "          x_train_trans = copy.copy(x_train)\n",
        "          x_train_trans = x_train_trans.astype(np.int64)\n",
        "          print('Transforming training dataset...')\n",
        "\n",
        "          for test in range(len(x_train_trans)):\n",
        "            a = np.random.uniform(low=0.0, high=1.0, size=(3,))\n",
        "            b = np.random.uniform(low=0.0, high=1.0, size=(3,))\n",
        "            c = np.random.uniform(low=0.0, high=1.0, size=(3,))\n",
        "            transform = np.array([a,b,c])\n",
        "\n",
        "            img = copy.copy(x_train[test])\n",
        "            img = img.astype(np.int64)\n",
        "\n",
        "            x_train_trans[test] = CCP_Attack_Brightness(img,transform)\n",
        "\n",
        "          print('\\nAugmented CCP Attacked Training Dataset!\\n')\n",
        "\n",
        "\n",
        "          x_train = np.vstack((x_train,x_train_trans))\n",
        "          y_train = np.vstack((y_train,y_train))\n",
        "\n",
        "        x_train = x_train.astype('float32')\n",
        "        x_test = x_test.astype('float32')\n",
        "        x_train, x_test = self.normalize(x_train, x_test)\n",
        "\n",
        "        y_train = keras.utils.to_categorical(y_train, self.num_classes)\n",
        "        y_test = keras.utils.to_categorical(y_test, self.num_classes)\n",
        "\n",
        "        def lr_scheduler(epoch):\n",
        "            return learning_rate * (0.5 ** (epoch // lr_drop))\n",
        "        reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
        "\n",
        "        datagen = ImageDataGenerator(\n",
        "            featurewise_center=False, \n",
        "            samplewise_center=False, \n",
        "            featurewise_std_normalization=False,  \n",
        "            samplewise_std_normalization=False, \n",
        "            zca_whitening=False,  \n",
        "            rotation_range=15,  \n",
        "            width_shift_range=0.1,  \n",
        "            height_shift_range=0.1,  \n",
        "            horizontal_flip=True,  \n",
        "            vertical_flip=False)  \n",
        "        datagen.fit(x_train)\n",
        "\n",
        "\n",
        "        sgd = optimizers.SGD(lr=learning_rate, decay=lr_decay, momentum=0.9, nesterov=True)\n",
        "        model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=['accuracy'])\n",
        "\n",
        "\n",
        "        my_callbacks = [\n",
        "            tf.keras.callbacks.ModelCheckpoint(filepath='cifar10vgg_{epoch:02d}_{val_loss:.2f}.h5', save_best_only=True, period=10),\n",
        "            reduce_lr\n",
        "        ]\n",
        "\n",
        "        historytemp = model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                         batch_size=batch_size),\n",
        "                            steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "                            epochs=175,\n",
        "                            validation_data=(x_test, y_test),callbacks=my_callbacks,verbose=2)\n",
        "        model.save('cifar10vgg.h5')\n",
        "        return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kD8vn5u34VQD"
      },
      "outputs": [],
      "source": [
        "model = cifar10vgg(train=True, ccp_augment=False) # Change ccp_augment=False to ccp_augment=True for CCP augmented training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucPYasUO4Vwf"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "predicted_x = model.predict(x_test)\n",
        "residuals = np.argmax(predicted_x,1)!=np.argmax(y_test,1)\n",
        "\n",
        "loss = sum(residuals)/len(residuals)\n",
        "print(\"the validation 0/1 loss is: \",1-loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXprPZhR4Xr5"
      },
      "outputs": [],
      "source": [
        "def change_brightness(image, alpha, beta):\n",
        "  new_image = np.zeros(image.shape, np.int64)\n",
        "  new_image = np.clip( alpha*image + beta, 0, 255)\n",
        "  return new_image\n",
        "\t\n",
        "def CCP_Attack_Brightness(image, transform):\n",
        "\timg = copy.copy(image)\n",
        "\tfor channel in range(img.shape[2]):\n",
        "\t\ttemp1 = image[:,:,0]\n",
        "\t\ttemp2 = image[:,:,1]\n",
        "\t\ttemp3 = image[:,:,2]\n",
        "\n",
        "\t\ttemp = temp1 * transform[channel][0] + temp2 * transform[channel][1] + temp3 * transform[channel][2]\n",
        "\n",
        "\t\timg[:,:,channel] = temp/3\n",
        "\n",
        "\timg1 = change_brightness(img, 2, 0)\n",
        "\treturn img1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvO81Vpe4aV6"
      },
      "outputs": [],
      "source": [
        "(x_train1, y_train1), (x_test1, y_test1) = cifar10.load_data()\n",
        "\n",
        "a = np.random.uniform(low=0.0, high=1.0, size=(3,))\n",
        "b = np.random.uniform(low=0.0, high=1.0, size=(3,))\n",
        "c = np.random.uniform(low=0.0, high=1.0, size=(3,))\n",
        "transform1 = np.array([a,b,c])\n",
        "\n",
        "x_test1_trans = copy.copy(x_test1)\n",
        "x_test1_trans = x_test1_trans.astype(np.int64)\n",
        "\n",
        "for test in range(len(x_test1_trans)):\n",
        "  \n",
        "  img = copy.copy(x_test1[test])\n",
        "  img = img.astype(np.int64)\n",
        "\n",
        "  x_test1_trans[test] = CCP_Attack_Brightness(img,transform1)\n",
        "\n",
        "\n",
        "x_train1 = x_train1.astype('float32') / 255\n",
        "x_test1_trans = x_test1_trans.astype('float32') / 255\n",
        "\n",
        "\n",
        "y_train1 = keras.utils.to_categorical(y_train1, 10)\n",
        "y_test1 = keras.utils.to_categorical(y_test1, 10)\n",
        "\n",
        "predicted_x = model.predict(x_test1_trans)\n",
        "residuals = np.argmax(predicted_x,1)!=np.argmax(y_test,1)\n",
        "loss = sum(residuals)/len(residuals)\n",
        "print(\"the validation 0/1 loss (after CCP attack) is: \",1-loss)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "VGG16_CCP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
